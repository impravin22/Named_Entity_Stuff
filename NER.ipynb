{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4033d02e-604a-4ed1-9d4e-ac20a221d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss = 7464.9994\n",
      "Iteration 2: Loss = 7059.8011\n",
      "Iteration 3: Loss = 6612.6086\n",
      "Iteration 4: Loss = 5997.3302\n",
      "Iteration 5: Loss = 5230.9092\n",
      "Iteration 6: Loss = 4494.6776\n",
      "Iteration 7: Loss = 3462.4101\n",
      "Iteration 8: Loss = 2488.3178\n",
      "Iteration 9: Loss = 1726.7647\n",
      "Iteration 10: Loss = 1083.8068\n",
      "Iteration 11: Loss = 752.4566\n",
      "Iteration 12: Loss = 709.0855\n",
      "Iteration 13: Loss = 725.9492\n",
      "Iteration 14: Loss = 728.5426\n",
      "Iteration 15: Loss = 728.5735\n",
      "Iteration 16: Loss = 726.5783\n",
      "Iteration 17: Loss = 718.6747\n",
      "Iteration 18: Loss = 713.4544\n",
      "Iteration 19: Loss = 680.8307\n",
      "Iteration 20: Loss = 637.0411\n",
      "Iteration 21: Loss = 633.8739\n",
      "Iteration 22: Loss = 557.0887\n",
      "Iteration 23: Loss = 525.3083\n",
      "Iteration 24: Loss = 543.0165\n",
      "Iteration 25: Loss = 522.1714\n",
      "Iteration 26: Loss = 494.0352\n",
      "Iteration 27: Loss = 458.0407\n",
      "Iteration 28: Loss = 479.7428\n",
      "Iteration 29: Loss = 457.8049\n",
      "Iteration 30: Loss = 458.6211\n",
      "Iteration 31: Loss = 406.3428\n",
      "Iteration 32: Loss = 391.3163\n",
      "Iteration 33: Loss = 325.8084\n",
      "Iteration 34: Loss = 344.1599\n",
      "Iteration 35: Loss = 298.3062\n",
      "Iteration 36: Loss = 241.4216\n",
      "Iteration 37: Loss = 199.2800\n",
      "Iteration 38: Loss = 154.5524\n",
      "Iteration 39: Loss = 90.9069\n",
      "Iteration 40: Loss = 91.7965\n",
      "Iteration 41: Loss = 71.2356\n",
      "Iteration 42: Loss = 66.3370\n",
      "Iteration 43: Loss = 65.2792\n",
      "Iteration 44: Loss = 65.7078\n",
      "Iteration 45: Loss = 67.3790\n",
      "Iteration 46: Loss = 54.4515\n",
      "Iteration 47: Loss = 55.7712\n",
      "Iteration 48: Loss = 52.3539\n",
      "Iteration 49: Loss = 43.9745\n",
      "Iteration 50: Loss = 43.5450\n",
      "Iteration 51: Loss = 47.2969\n",
      "Iteration 52: Loss = 41.8881\n",
      "Iteration 53: Loss = 36.4588\n",
      "Iteration 54: Loss = 32.9131\n",
      "Iteration 55: Loss = 45.0969\n",
      "Iteration 56: Loss = 32.3955\n",
      "Iteration 57: Loss = 31.9773\n",
      "Iteration 58: Loss = 32.8174\n",
      "Iteration 59: Loss = 37.6787\n",
      "Iteration 60: Loss = 32.4799\n",
      "Iteration 61: Loss = 37.0382\n",
      "Iteration 62: Loss = 45.6745\n",
      "Iteration 63: Loss = 37.4558\n",
      "Iteration 64: Loss = 31.4453\n",
      "Iteration 65: Loss = 21.1145\n",
      "Iteration 66: Loss = 19.4645\n",
      "Iteration 67: Loss = 31.9536\n",
      "Iteration 68: Loss = 13.7522\n",
      "Iteration 69: Loss = 23.7380\n",
      "Iteration 70: Loss = 18.9879\n",
      "Iteration 71: Loss = 6.9154\n",
      "Iteration 72: Loss = 4.4676\n",
      "Iteration 73: Loss = 6.6193\n",
      "Iteration 74: Loss = 5.5110\n",
      "Iteration 75: Loss = 2.9614\n",
      "Iteration 76: Loss = 4.1962\n",
      "Iteration 77: Loss = 1.0443\n",
      "Iteration 78: Loss = 1.0181\n",
      "Iteration 79: Loss = 5.7713\n",
      "Iteration 80: Loss = 0.6548\n",
      "Iteration 81: Loss = 2.2106\n",
      "Iteration 82: Loss = 3.0287\n",
      "Iteration 83: Loss = 6.8305\n",
      "Iteration 84: Loss = 3.8191\n",
      "Iteration 85: Loss = 0.8124\n",
      "Iteration 86: Loss = 1.4552\n",
      "Iteration 87: Loss = 1.4505\n",
      "Iteration 88: Loss = 1.2326\n",
      "Iteration 89: Loss = 0.1547\n",
      "Iteration 90: Loss = 0.0487\n",
      "Iteration 91: Loss = 0.0823\n",
      "Iteration 92: Loss = 1.2449\n",
      "Iteration 93: Loss = 1.6443\n",
      "Iteration 94: Loss = 0.0056\n",
      "Iteration 95: Loss = 6.5834\n",
      "Iteration 96: Loss = 0.0516\n",
      "Iteration 97: Loss = 0.3881\n",
      "Iteration 98: Loss = 3.0299\n",
      "Iteration 99: Loss = 1.2462\n",
      "Iteration 100: Loss = 1.3332\n",
      "Fold 1 Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'TERMINOLOGY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'speed': 16438.761694552366}\n",
      "Iteration 1: Loss = 6168.3332\n",
      "Iteration 2: Loss = 5821.2077\n",
      "Iteration 3: Loss = 5457.5046\n",
      "Iteration 4: Loss = 4927.9163\n",
      "Iteration 5: Loss = 4300.8184\n",
      "Iteration 6: Loss = 3562.1318\n",
      "Iteration 7: Loss = 2818.3155\n",
      "Iteration 8: Loss = 1788.4051\n",
      "Iteration 9: Loss = 956.2595\n",
      "Iteration 10: Loss = 664.2060\n",
      "Iteration 11: Loss = 559.7305\n",
      "Iteration 12: Loss = 547.1933\n",
      "Iteration 13: Loss = 541.7871\n",
      "Iteration 14: Loss = 547.5792\n",
      "Iteration 15: Loss = 542.6995\n",
      "Iteration 16: Loss = 542.4917\n",
      "Iteration 17: Loss = 527.5050\n",
      "Iteration 18: Loss = 521.8344\n",
      "Iteration 19: Loss = 492.5387\n",
      "Iteration 20: Loss = 497.4536\n",
      "Iteration 21: Loss = 490.1540\n",
      "Iteration 22: Loss = 461.1417\n",
      "Iteration 23: Loss = 461.2875\n",
      "Iteration 24: Loss = 435.5336\n",
      "Iteration 25: Loss = 403.5751\n",
      "Iteration 26: Loss = 382.7385\n",
      "Iteration 27: Loss = 371.5515\n",
      "Iteration 28: Loss = 389.1891\n",
      "Iteration 29: Loss = 379.5308\n",
      "Iteration 30: Loss = 376.8245\n",
      "Iteration 31: Loss = 339.1227\n",
      "Iteration 32: Loss = 312.1044\n",
      "Iteration 33: Loss = 321.1882\n",
      "Iteration 34: Loss = 279.7111\n",
      "Iteration 35: Loss = 265.4325\n",
      "Iteration 36: Loss = 215.4164\n",
      "Iteration 37: Loss = 184.4980\n",
      "Iteration 38: Loss = 172.7868\n",
      "Iteration 39: Loss = 138.7989\n",
      "Iteration 40: Loss = 114.2189\n",
      "Iteration 41: Loss = 99.3713\n",
      "Iteration 42: Loss = 59.3058\n",
      "Iteration 43: Loss = 60.8472\n",
      "Iteration 44: Loss = 59.3189\n",
      "Iteration 45: Loss = 52.5039\n",
      "Iteration 46: Loss = 46.6786\n",
      "Iteration 47: Loss = 46.8224\n",
      "Iteration 48: Loss = 35.7934\n",
      "Iteration 49: Loss = 40.0917\n",
      "Iteration 50: Loss = 42.9868\n",
      "Iteration 51: Loss = 29.9537\n",
      "Iteration 52: Loss = 27.8666\n",
      "Iteration 53: Loss = 28.9643\n",
      "Iteration 54: Loss = 26.8699\n",
      "Iteration 55: Loss = 30.2280\n",
      "Iteration 56: Loss = 30.1908\n",
      "Iteration 57: Loss = 29.2220\n",
      "Iteration 58: Loss = 26.1484\n",
      "Iteration 59: Loss = 27.6574\n",
      "Iteration 60: Loss = 23.8388\n",
      "Iteration 61: Loss = 33.2086\n",
      "Iteration 62: Loss = 32.8262\n",
      "Iteration 63: Loss = 36.4014\n",
      "Iteration 64: Loss = 26.1799\n",
      "Iteration 65: Loss = 30.8920\n",
      "Iteration 66: Loss = 35.0926\n",
      "Iteration 67: Loss = 38.9755\n",
      "Iteration 68: Loss = 39.6351\n",
      "Iteration 69: Loss = 35.8206\n",
      "Iteration 70: Loss = 41.7484\n",
      "Iteration 71: Loss = 38.3156\n",
      "Iteration 72: Loss = 40.7569\n",
      "Iteration 73: Loss = 34.7199\n",
      "Iteration 74: Loss = 30.1023\n",
      "Iteration 75: Loss = 23.3912\n",
      "Iteration 76: Loss = 24.9825\n",
      "Iteration 77: Loss = 59.2095\n",
      "Iteration 78: Loss = 22.3219\n",
      "Iteration 79: Loss = 57.4571\n",
      "Iteration 80: Loss = 29.3569\n",
      "Iteration 81: Loss = 26.8703\n",
      "Iteration 82: Loss = 7.3000\n",
      "Iteration 83: Loss = 7.8759\n",
      "Iteration 84: Loss = 6.7975\n",
      "Iteration 85: Loss = 2.0683\n",
      "Iteration 86: Loss = 5.3691\n",
      "Iteration 87: Loss = 3.0931\n",
      "Iteration 88: Loss = 1.4340\n",
      "Iteration 89: Loss = 0.7772\n",
      "Iteration 90: Loss = 4.2650\n",
      "Iteration 91: Loss = 1.0497\n",
      "Iteration 92: Loss = 4.4224\n",
      "Iteration 93: Loss = 1.5604\n",
      "Iteration 94: Loss = 0.2127\n",
      "Iteration 95: Loss = 0.0407\n",
      "Iteration 96: Loss = 0.0485\n",
      "Iteration 97: Loss = 1.2003\n",
      "Iteration 98: Loss = 0.6537\n",
      "Iteration 99: Loss = 1.9151\n",
      "Iteration 100: Loss = 0.0017\n",
      "Fold 2 Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.991304347826087, 'ents_r': 1.0, 'ents_f': 0.9956331877729258, 'ents_per_type': {'TERMINOLOGY': {'p': 0.991304347826087, 'r': 1.0, 'f': 0.9956331877729258}}, 'speed': 17199.59046564829}\n",
      "Iteration 1: Loss = 5992.1665\n",
      "Iteration 2: Loss = 5629.0938\n",
      "Iteration 3: Loss = 5139.7507\n",
      "Iteration 4: Loss = 4642.5518\n",
      "Iteration 5: Loss = 4015.3169\n",
      "Iteration 6: Loss = 3335.8679\n",
      "Iteration 7: Loss = 2507.6501\n",
      "Iteration 8: Loss = 1704.9924\n",
      "Iteration 9: Loss = 1144.1456\n",
      "Iteration 10: Loss = 819.4764\n",
      "Iteration 11: Loss = 653.0370\n",
      "Iteration 12: Loss = 623.6470\n",
      "Iteration 13: Loss = 633.0801\n",
      "Iteration 14: Loss = 619.0784\n",
      "Iteration 15: Loss = 624.9926\n",
      "Iteration 16: Loss = 622.1991\n",
      "Iteration 17: Loss = 609.7787\n",
      "Iteration 18: Loss = 605.4431\n",
      "Iteration 19: Loss = 595.1741\n",
      "Iteration 20: Loss = 570.9884\n",
      "Iteration 21: Loss = 539.0663\n",
      "Iteration 22: Loss = 533.8513\n",
      "Iteration 23: Loss = 501.7526\n",
      "Iteration 24: Loss = 504.1401\n",
      "Iteration 25: Loss = 454.1408\n",
      "Iteration 26: Loss = 453.4879\n",
      "Iteration 27: Loss = 387.6854\n",
      "Iteration 28: Loss = 412.4297\n",
      "Iteration 29: Loss = 599.5724\n",
      "Iteration 30: Loss = 372.7225\n",
      "Iteration 31: Loss = 457.7603\n",
      "Iteration 32: Loss = 329.7551\n",
      "Iteration 33: Loss = 343.2347\n",
      "Iteration 34: Loss = 225.5386\n",
      "Iteration 35: Loss = 214.6459\n",
      "Iteration 36: Loss = 176.4363\n",
      "Iteration 37: Loss = 171.7851\n",
      "Iteration 38: Loss = 120.1824\n",
      "Iteration 39: Loss = 86.2655\n",
      "Iteration 40: Loss = 76.1979\n",
      "Iteration 41: Loss = 60.1485\n",
      "Iteration 42: Loss = 74.7630\n",
      "Iteration 43: Loss = 66.5959\n",
      "Iteration 44: Loss = 69.6044\n",
      "Iteration 45: Loss = 60.2585\n",
      "Iteration 46: Loss = 44.8934\n",
      "Iteration 47: Loss = 58.1013\n",
      "Iteration 48: Loss = 53.3188\n",
      "Iteration 49: Loss = 48.2004\n",
      "Iteration 50: Loss = 44.7507\n",
      "Iteration 51: Loss = 51.4814\n",
      "Iteration 52: Loss = 40.8650\n",
      "Iteration 53: Loss = 37.0732\n",
      "Iteration 54: Loss = 49.9687\n",
      "Iteration 55: Loss = 32.1155\n",
      "Iteration 56: Loss = 31.6003\n",
      "Iteration 57: Loss = 41.8584\n",
      "Iteration 58: Loss = 33.9751\n",
      "Iteration 59: Loss = 41.7199\n",
      "Iteration 60: Loss = 33.5292\n",
      "Iteration 61: Loss = 54.9824\n",
      "Iteration 62: Loss = 45.0523\n",
      "Iteration 63: Loss = 49.9157\n",
      "Iteration 64: Loss = 45.4954\n",
      "Iteration 65: Loss = 43.3418\n",
      "Iteration 66: Loss = 57.2347\n",
      "Iteration 67: Loss = 39.8925\n",
      "Iteration 68: Loss = 33.0237\n",
      "Iteration 69: Loss = 10.4376\n",
      "Iteration 70: Loss = 5.8912\n",
      "Iteration 71: Loss = 5.8323\n",
      "Iteration 72: Loss = 11.1655\n",
      "Iteration 73: Loss = 3.8927\n",
      "Iteration 74: Loss = 3.3619\n",
      "Iteration 75: Loss = 2.2202\n",
      "Iteration 76: Loss = 3.3804\n",
      "Iteration 77: Loss = 1.2201\n",
      "Iteration 78: Loss = 2.9298\n",
      "Iteration 79: Loss = 0.7270\n",
      "Iteration 80: Loss = 1.7514\n",
      "Iteration 81: Loss = 0.0639\n",
      "Iteration 82: Loss = 0.6403\n",
      "Iteration 83: Loss = 1.8149\n",
      "Iteration 84: Loss = 2.4409\n",
      "Iteration 85: Loss = 0.5346\n",
      "Iteration 86: Loss = 9.6934\n",
      "Iteration 87: Loss = 2.0635\n",
      "Iteration 88: Loss = 0.0208\n",
      "Iteration 89: Loss = 0.0031\n",
      "Iteration 90: Loss = 2.1017\n",
      "Iteration 91: Loss = 0.0181\n",
      "Iteration 92: Loss = 0.0783\n",
      "Iteration 93: Loss = 1.3872\n",
      "Iteration 94: Loss = 0.0021\n",
      "Iteration 95: Loss = 0.0020\n",
      "Iteration 96: Loss = 0.0413\n",
      "Iteration 97: Loss = 0.0487\n",
      "Iteration 98: Loss = 3.5047\n",
      "Iteration 99: Loss = 0.0324\n",
      "Iteration 100: Loss = 0.0002\n",
      "Fold 3 Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'TERMINOLOGY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'speed': 16981.983376338656}\n",
      "Iteration 1: Loss = 4146.6662\n",
      "Iteration 2: Loss = 3958.9070\n",
      "Iteration 3: Loss = 3675.3472\n",
      "Iteration 4: Loss = 3354.5450\n",
      "Iteration 5: Loss = 2967.5992\n",
      "Iteration 6: Loss = 2518.5400\n",
      "Iteration 7: Loss = 2015.8321\n",
      "Iteration 8: Loss = 1327.4376\n",
      "Iteration 9: Loss = 1116.1239\n",
      "Iteration 10: Loss = 814.5195\n",
      "Iteration 11: Loss = 540.9023\n",
      "Iteration 12: Loss = 454.6628\n",
      "Iteration 13: Loss = 430.1727\n",
      "Iteration 14: Loss = 439.9696\n",
      "Iteration 15: Loss = 434.2807\n",
      "Iteration 16: Loss = 440.0311\n",
      "Iteration 17: Loss = 426.4620\n",
      "Iteration 18: Loss = 430.7162\n",
      "Iteration 19: Loss = 420.3989\n",
      "Iteration 20: Loss = 405.9471\n",
      "Iteration 21: Loss = 384.8908\n",
      "Iteration 22: Loss = 361.7665\n",
      "Iteration 23: Loss = 347.7418\n",
      "Iteration 24: Loss = 367.2901\n",
      "Iteration 25: Loss = 330.1572\n",
      "Iteration 26: Loss = 342.7462\n",
      "Iteration 27: Loss = 304.5106\n",
      "Iteration 28: Loss = 312.2423\n",
      "Iteration 29: Loss = 281.4458\n",
      "Iteration 30: Loss = 283.9467\n",
      "Iteration 31: Loss = 252.2069\n",
      "Iteration 32: Loss = 277.4612\n",
      "Iteration 33: Loss = 226.9871\n",
      "Iteration 34: Loss = 217.7472\n",
      "Iteration 35: Loss = 200.2686\n",
      "Iteration 36: Loss = 179.9374\n",
      "Iteration 37: Loss = 164.7749\n",
      "Iteration 38: Loss = 134.5549\n",
      "Iteration 39: Loss = 116.2113\n",
      "Iteration 40: Loss = 105.8711\n",
      "Iteration 41: Loss = 81.8996\n",
      "Iteration 42: Loss = 75.3383\n",
      "Iteration 43: Loss = 69.0270\n",
      "Iteration 44: Loss = 74.4187\n",
      "Iteration 45: Loss = 63.6424\n",
      "Iteration 46: Loss = 59.3198\n",
      "Iteration 47: Loss = 57.1864\n",
      "Iteration 48: Loss = 60.6754\n",
      "Iteration 49: Loss = 44.8687\n",
      "Iteration 50: Loss = 42.1398\n",
      "Iteration 51: Loss = 43.8080\n",
      "Iteration 52: Loss = 41.7927\n",
      "Iteration 53: Loss = 46.3972\n",
      "Iteration 54: Loss = 49.3484\n",
      "Iteration 55: Loss = 52.3204\n",
      "Iteration 56: Loss = 57.4967\n",
      "Iteration 57: Loss = 64.1044\n",
      "Iteration 58: Loss = 54.6781\n",
      "Iteration 59: Loss = 52.2032\n",
      "Iteration 60: Loss = 48.5622\n",
      "Iteration 61: Loss = 29.4889\n",
      "Iteration 62: Loss = 19.9306\n",
      "Iteration 63: Loss = 59.2823\n",
      "Iteration 64: Loss = 44.5823\n",
      "Iteration 65: Loss = 38.2678\n",
      "Iteration 66: Loss = 21.2886\n",
      "Iteration 67: Loss = 14.2299\n",
      "Iteration 68: Loss = 4.6222\n",
      "Iteration 69: Loss = 3.6513\n",
      "Iteration 70: Loss = 7.4972\n",
      "Iteration 71: Loss = 3.9331\n",
      "Iteration 72: Loss = 7.1629\n",
      "Iteration 73: Loss = 5.5318\n",
      "Iteration 74: Loss = 5.6765\n",
      "Iteration 75: Loss = 2.6811\n",
      "Iteration 76: Loss = 3.9244\n",
      "Iteration 77: Loss = 6.6577\n",
      "Iteration 78: Loss = 3.2898\n",
      "Iteration 79: Loss = 0.9662\n",
      "Iteration 80: Loss = 1.4508\n",
      "Iteration 81: Loss = 1.1775\n",
      "Iteration 82: Loss = 0.0952\n",
      "Iteration 83: Loss = 2.7429\n",
      "Iteration 84: Loss = 3.0896\n",
      "Iteration 85: Loss = 1.3721\n",
      "Iteration 86: Loss = 1.3945\n",
      "Iteration 87: Loss = 0.0030\n",
      "Iteration 88: Loss = 0.0126\n",
      "Iteration 89: Loss = 1.4197\n",
      "Iteration 90: Loss = 0.3485\n",
      "Iteration 91: Loss = 1.3442\n",
      "Iteration 92: Loss = 1.2080\n",
      "Iteration 93: Loss = 2.1226\n",
      "Iteration 94: Loss = 0.0023\n",
      "Iteration 95: Loss = 0.8359\n",
      "Iteration 96: Loss = 0.4716\n",
      "Iteration 97: Loss = 0.0730\n",
      "Iteration 98: Loss = 0.0194\n",
      "Iteration 99: Loss = 1.9829\n",
      "Iteration 100: Loss = 1.0289\n",
      "Fold 4 Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'TERMINOLOGY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'speed': 17061.69914768898}\n",
      "Iteration 1: Loss = 7688.3326\n",
      "Iteration 2: Loss = 7356.7015\n",
      "Iteration 3: Loss = 6811.4988\n",
      "Iteration 4: Loss = 6201.0585\n",
      "Iteration 5: Loss = 5330.4371\n",
      "Iteration 6: Loss = 4478.9093\n",
      "Iteration 7: Loss = 3701.2846\n",
      "Iteration 8: Loss = 2283.8058\n",
      "Iteration 9: Loss = 1925.1065\n",
      "Iteration 10: Loss = 1216.0494\n",
      "Iteration 11: Loss = 797.7619\n",
      "Iteration 12: Loss = 757.7692\n",
      "Iteration 13: Loss = 738.2510\n",
      "Iteration 14: Loss = 744.9200\n",
      "Iteration 15: Loss = 742.0566\n",
      "Iteration 16: Loss = 741.5056\n",
      "Iteration 17: Loss = 725.7585\n",
      "Iteration 18: Loss = 730.4142\n",
      "Iteration 19: Loss = 731.7652\n",
      "Iteration 20: Loss = 703.5829\n",
      "Iteration 21: Loss = 655.0588\n",
      "Iteration 22: Loss = 665.4937\n",
      "Iteration 23: Loss = 627.7077\n",
      "Iteration 24: Loss = 647.6078\n",
      "Iteration 25: Loss = 602.9699\n",
      "Iteration 26: Loss = 574.6197\n",
      "Iteration 27: Loss = 561.9008\n",
      "Iteration 28: Loss = 562.2122\n",
      "Iteration 29: Loss = 503.0569\n",
      "Iteration 30: Loss = 480.1105\n",
      "Iteration 31: Loss = 455.5348\n",
      "Iteration 32: Loss = 463.4341\n",
      "Iteration 33: Loss = 435.2400\n",
      "Iteration 34: Loss = 447.3187\n",
      "Iteration 35: Loss = 401.2307\n",
      "Iteration 36: Loss = 386.5285\n",
      "Iteration 37: Loss = 319.6152\n",
      "Iteration 38: Loss = 280.6945\n",
      "Iteration 39: Loss = 231.2833\n",
      "Iteration 40: Loss = 176.4280\n",
      "Iteration 41: Loss = 152.5174\n",
      "Iteration 42: Loss = 127.7703\n",
      "Iteration 43: Loss = 113.4844\n",
      "Iteration 44: Loss = 99.0290\n",
      "Iteration 45: Loss = 67.6156\n",
      "Iteration 46: Loss = 78.4172\n",
      "Iteration 47: Loss = 76.0098\n",
      "Iteration 48: Loss = 68.4792\n",
      "Iteration 49: Loss = 52.9088\n",
      "Iteration 50: Loss = 56.2274\n",
      "Iteration 51: Loss = 48.6025\n",
      "Iteration 52: Loss = 52.5561\n",
      "Iteration 53: Loss = 50.7679\n",
      "Iteration 54: Loss = 43.5237\n",
      "Iteration 55: Loss = 37.9928\n",
      "Iteration 56: Loss = 34.4652\n",
      "Iteration 57: Loss = 38.0656\n",
      "Iteration 58: Loss = 36.3732\n",
      "Iteration 59: Loss = 30.8047\n",
      "Iteration 60: Loss = 34.4765\n",
      "Iteration 61: Loss = 34.7154\n",
      "Iteration 62: Loss = 31.1936\n",
      "Iteration 63: Loss = 38.0481\n",
      "Iteration 64: Loss = 28.5764\n",
      "Iteration 65: Loss = 29.3958\n",
      "Iteration 66: Loss = 32.8652\n",
      "Iteration 67: Loss = 25.7590\n",
      "Iteration 68: Loss = 17.1409\n",
      "Iteration 69: Loss = 13.0729\n",
      "Iteration 70: Loss = 15.0438\n",
      "Iteration 71: Loss = 11.6050\n",
      "Iteration 72: Loss = 17.0388\n",
      "Iteration 73: Loss = 10.2286\n",
      "Iteration 74: Loss = 8.6127\n",
      "Iteration 75: Loss = 5.1556\n",
      "Iteration 76: Loss = 6.5949\n",
      "Iteration 77: Loss = 6.5873\n",
      "Iteration 78: Loss = 1.4590\n",
      "Iteration 79: Loss = 1.8899\n",
      "Iteration 80: Loss = 2.5497\n",
      "Iteration 81: Loss = 1.1033\n",
      "Iteration 82: Loss = 1.5873\n",
      "Iteration 83: Loss = 7.3527\n",
      "Iteration 84: Loss = 0.9039\n",
      "Iteration 85: Loss = 2.6642\n",
      "Iteration 86: Loss = 2.5854\n",
      "Iteration 87: Loss = 0.9127\n",
      "Iteration 88: Loss = 2.8645\n",
      "Iteration 89: Loss = 0.2539\n",
      "Iteration 90: Loss = 0.7524\n",
      "Iteration 91: Loss = 5.5244\n",
      "Iteration 92: Loss = 2.0920\n",
      "Iteration 93: Loss = 2.0312\n",
      "Iteration 94: Loss = 0.0091\n",
      "Iteration 95: Loss = 0.1404\n",
      "Iteration 96: Loss = 0.9444\n",
      "Iteration 97: Loss = 3.1451\n",
      "Iteration 98: Loss = 2.0470\n",
      "Iteration 99: Loss = 0.4149\n",
      "Iteration 100: Loss = 0.0012\n",
      "Fold 5 Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'TERMINOLOGY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'speed': 14653.407517409352}\n",
      "Best F1 Score: 1.0\n",
      "Tagged Data: [('TensorFlow', 'TERMINOLOGY'), ('Google', 'TERMINOLOGY'), ('Python', 'TERMINOLOGY'), ('machine learning', 'TERMINOLOGY')]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import spacy.matcher\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "# Step 1: Data Collection\n",
    "def collect_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    text_data = \" \".join([p.get_text() for p in soup.find_all(\"p\")])\n",
    "    return text_data\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "def preprocess_data(text_data):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc = nlp(text_data)\n",
    "    preprocessed_data = \" \".join([token.text.lower() for token in doc if not token.is_punct])\n",
    "    return preprocessed_data\n",
    "\n",
    "def annotate_data(nlp, text_data, named_entities):\n",
    "    matcher = spacy.matcher.PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "    patterns = [nlp.make_doc(entity) for entity in named_entities]\n",
    "    matcher.add(\"TerminologyList\", patterns)\n",
    "    \n",
    "    doc = nlp(text_data)\n",
    "    matches = matcher(doc)\n",
    "    spans = [doc[start:end] for _, start, end in matches]\n",
    "    filtered_spans = spacy.util.filter_spans(spans)\n",
    "    entities = [(span.start_char, span.end_char, \"TERMINOLOGY\") for span in filtered_spans]\n",
    "    \n",
    "    return Example.from_dict(doc, {\"entities\": entities})\n",
    "\n",
    "# Model Training\n",
    "def train_model(annotated_data, iterations):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\")\n",
    "    ner.add_label(\"TERMINOLOGY\")\n",
    "\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            losses = {}\n",
    "            examples = [example for example in annotated_data]\n",
    "            nlp.update(examples, sgd=optimizer, drop=0.5, losses=losses)\n",
    "            print(f\"Iteration {itn + 1}: Loss = {losses['ner']:.4f}\")\n",
    "    return nlp\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(nlp, test_data):\n",
    "    scores = nlp.evaluate(test_data)\n",
    "    return scores\n",
    "\n",
    "def tag_raw_data(model, raw_data):\n",
    "    doc = model(raw_data)\n",
    "    tagged_data = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return tagged_data\n",
    "\n",
    "def main():\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    training_urls = [\n",
    "        \"https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/toolkit\",\n",
    "        \"https://en.wikipedia.org/wiki/TensorFlow\",\n",
    "        \"https://www.tensorflow.org/learn\",\n",
    "        \"https://en.wikipedia.org/wiki/Google_Brain\",\n",
    "        \"https://en.wikipedia.org/wiki/Python_(programming_language)\",\n",
    "            # Add more URLs with relevant content\n",
    "    ]\n",
    "    named_entities = [\"TensorFlow\", \"Google\", \"Python\", \"Machine Learning\"]\n",
    "\n",
    "    annotated_data = []\n",
    "    for url in training_urls:\n",
    "        text_data = collect_data(url)\n",
    "        preprocessed_data = preprocess_data(text_data)\n",
    "        annotated_data.append(annotate_data(nlp, preprocessed_data, named_entities))\n",
    "\n",
    "    # Shuffle and split the data for cross-validation\n",
    "\n",
    "    # random.shuffle(annotated_data)\n",
    "    # Shuffle and prepare for cross-validation\n",
    "    random.shuffle(annotated_data)\n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    best_f1_score = -1\n",
    "    best_model_path = \"\"\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(annotated_data)):\n",
    "        train_data = [annotated_data[i] for i in train_index]\n",
    "        test_data = [annotated_data[i] for i in test_index]\n",
    "        \n",
    "        # Train model on this fold's training data\n",
    "        model = train_model(train_data, iterations=100)\n",
    "        \n",
    "        # Evaluate model on this fold's test data\n",
    "        evaluation_results = evaluate_model(model, test_data)\n",
    "        print(f\"Fold {fold+1} Evaluation Results: {evaluation_results}\")\n",
    "        \n",
    "        # Check if this model is the best so far\n",
    "        if evaluation_results['ents_f'] > best_f1_score:\n",
    "            best_f1_score = evaluation_results['ents_f']\n",
    "            best_model_path = f\"best_model_fold_{fold+1}\"\n",
    "            model.to_disk(best_model_path)\n",
    "    \n",
    "    print(f\"Best F1 Score: {best_f1_score}\")\n",
    "    \n",
    "    # Load the best model from disk\n",
    "    best_model = spacy.load(best_model_path)\n",
    "    \n",
    "    # Model Deployment and Tagging with the best model\n",
    "    sample_text = \"TensorFlow, developed by Google, is widely used in Python programming for machine learning projects, often requiring GPU acceleration.\"\n",
    "    tagged_data = tag_raw_data(best_model, sample_text)\n",
    "    print(\"Tagged Data:\", tagged_data)\n",
    "\n",
    "    # kf = KFold(n_splits=5)  # 5-fold cross-validation\n",
    "    # for train_index, test_index in kf.split(annotated_data):\n",
    "    #     train_data = [annotated_data[i] for i in train_index]\n",
    "    #     test_data = [annotated_data[i] for i in test_index]\n",
    "    #     model = train_model(train_data, iterations=30)\n",
    "    #     evaluation_results = evaluate_model(model, test_data)\n",
    "    #     print(f\"Evaluation Results: {evaluation_results}\")\n",
    "\n",
    "    # # After cross-validation, train a final model on all data\n",
    "    # final_model = train_model(annotated_data, iterations=200)\n",
    "\n",
    "    # # Model Deployment and Tagging\n",
    "    # sample_text = \"TensorFlow, developed by Google, is widely used in Python programming for machine learning projects, often requiring GPU acceleration.\"\n",
    "    # tagged_data = tag_raw_data(final_model, sample_text)\n",
    "    # print(\"Tagged Data:\", tagged_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8020e61-7b4a-446f-9013-1aada31bc64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
